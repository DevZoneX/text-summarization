{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/users/eleves-a/2022/zakaria.abboud/.cache/huggingface\n",
      "New cache directory: /Data/zakaria.abboud/.cache/huggingface\n",
      "Path from root: /Data/zakaria.abboud/.cache/huggingface\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "cache_dir = os.getenv(\"HF_HOME\", os.path.expanduser(\"~/.cache/huggingface\"))\n",
    "print(cache_dir)\n",
    "os.chdir(\"/\")\n",
    "new_cache_dir = \"/Data/zakaria.abboud/.cache/huggingface\"\n",
    "if not os.path.exists(new_cache_dir):\n",
    "    os.makedirs(new_cache_dir, exist_ok=True)\n",
    "\n",
    "# Set the new cache directory\n",
    "os.environ[\"HF_HOME\"] = new_cache_dir\n",
    "print(f\"New cache directory: {new_cache_dir}\")\n",
    "print(f\"Path from root: {os.path.abspath(new_cache_dir)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pprint import pprint\n",
    "\n",
    "import bitsandbytes as bnb\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import transformers\n",
    "from datasets import Dataset\n",
    "from trl import DPOConfig, DPOTrainer\n",
    "\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    PeftConfig,\n",
    "    PeftModel,\n",
    "    get_peft_model,\n",
    "    prepare_model_for_kbit_training,\n",
    ")\n",
    "from transformers import (\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    AutoTokenizer,\n",
    "    BitsAndBytesConfig,\n",
    ")\n",
    "\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "# MODEL_NAME = \"unsloth/Llama-3.2-1B\" # Try Llama if you want\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\"\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    quantization_config=bnb_config,\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 13271040 || all params: 328390528 || trainable%: 4.041237145548851\n"
     ]
    }
   ],
   "source": [
    "def print_trainable_parameters(model):\n",
    "\n",
    "    \"\"\"\n",
    "    Prints the number of trainable parameters in the model.\n",
    "    \"\"\"\n",
    "    trainable_params = 0\n",
    "    all_param = 0\n",
    "    for _, param in model.named_parameters():\n",
    "        all_param += param.numel()\n",
    "        if param.requires_grad:\n",
    "            trainable_params += param.numel()\n",
    "    print(\n",
    "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
    "    )\n",
    "\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules = [\"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "model = PeftModel(model, peft_config=config)\n",
    "print_trainable_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['title', 'content', 'chosen', 'rejected'],\n",
       "    num_rows: 3938\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = json.load(open(\"/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/data/train.json\"))\n",
    "val_dataset = json.load(open(\"/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/data/val.json\"))\n",
    "test_dataset = json.load(open(\"/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/data/test.json\"))\n",
    "\n",
    "train_dataset = Dataset.from_list(train_dataset)\n",
    "val_dataset = Dataset.from_list(val_dataset)\n",
    "test_dataset = Dataset.from_list(test_dataset)\n",
    "\n",
    "train_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52c8d2aab6e842a88318fa53a25e33c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def generate_prompt(data_point):\n",
    "\n",
    "    prompt = f\"<human>: Summarize the following text :\\n\\n {data_point['content']}\\n\\nYou should respond in French, with 5 sentences maximum.\\n\\n<assistant>:\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "def generate_and_tokenize_prompt(data_point):\n",
    "    full_prompt = generate_prompt(data_point)+tokenizer.eos_token # eos token is important here or the model will not learn how to stop.\n",
    "    tokenized_full_prompt = tokenizer(full_prompt, return_tensors='pt')\n",
    "    ## FILL THE GAP: create the labels first by cloning input_ids\n",
    "    labels = tokenized_full_prompt.input_ids.clone()\n",
    "\n",
    "    prompt = full_prompt[:full_prompt.find(\"<assistant>\")] + \"<assistant>:\"\n",
    "    end_prompt_idx = prompt.find(\"<assistant>:\")\n",
    "\n",
    "    labels[:, :end_prompt_idx] = -100\n",
    "\n",
    "    return {\n",
    "        'input_ids': tokenized_full_prompt.input_ids.flatten(),\n",
    "        'labels': labels.flatten(),\n",
    "        'attention_mask': tokenized_full_prompt.attention_mask.flatten(),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e99a32bb7c14ae68bb2f0b73a6d37b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5eedccc30546b097c38af2c05597e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/493 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "151a4ff3a1b04ad9ac3e5dcd381aa6da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/492 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def preprocess_data_dpo(data_point):\n",
    "\n",
    "    system = \"You are a helpfull assistant, and you are asked to summarize the following text in French. You should respond with 5 sentences maximum:\\n\\n\"\n",
    "\n",
    "    return {\n",
    "            \"chosen\": [\n",
    "                {'role': 'user', 'content': system +\"\\n\"+ data_point[\"content\"]},\n",
    "                {'role': 'assistant', 'content': data_point[\"chosen\"]}\n",
    "            ],\n",
    "            \"rejected\": [\n",
    "                {'role': 'user', 'content': system +\"\\n\"+ data_point[\"content\"]},\n",
    "                {'role': 'assistant', 'content': data_point[\"rejected\"]}\n",
    "            ],\n",
    "        }\n",
    "\n",
    "data_dpo = train_dataset.shuffle(seed=42).map(preprocess_data_dpo)\n",
    "val_dpo = val_dataset.shuffle(seed=42).map(preprocess_data_dpo)\n",
    "test_dpo = test_dataset.shuffle(seed=42).map(preprocess_data_dpo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['title', 'content', 'chosen', 'rejected'],\n",
      "    num_rows: 3938\n",
      "})\n",
      "{'title': 'Bouctouche (Part 2)', 'content': \"é Michaud (Bouctouche, 1912 - ?, 1978), agriculteur, marchand et homme politique;\\nJoseph Michaud (1841-1903), prêtre, mort à Bouctouche ;\\nMarguerite Michaud (Bouctouche, 1903 - 1982), enseignante, administratrice, conférencière et écrivaine;\\nAuguste Renaud (Bordeaux, 1835 - Bouctouche, 1897), agriculteur et homme politique.\\nPaul Dwayne (Bouctouche, 1964 - 2024), chanteur de musique country, né à Bouctouche.\\nL’Hon. Stephen J. Doucet (Bouctouche, 1967-?), Juge de la Cour du Banc du Roi du Nouveau-Brunswick.\\n\\n\\n=== Architecture et monuments ===\\n\\nBouctouche possède une architecture variée mais dominée par le style traditionnel acadien. Toutefois, l'usine Fantech possède l'un des meilleurs exemples de mur-rideau de la province.\\nL'ancien bureau de poste est situé au 59, boulevard Irving. C'est un édifice en briques de deux étages. Il fut conçu et construit en 1929 par l'architecte Anselme Roy, dont les principales réalisations sont de nombreuses écoles, l'église Saint-Jean-Baptiste de Bouctouche, le manoir Irving et les premières stations-service caractéristiques d'Irving Oil. L'édifice fut occupé par le bureau des postes et douanes entre 1929 et les années 1960, par le premier hôtel de ville au début des années 1970 et ensuite par différents organismes dont Entreprises Kent depuis 1974.\\nLe couvent de l'Immaculée-Conception et sa chapelle du Sacré-Cœur est un site historique provincial.\\nL'église anglicane Saint Lawrence est un site historique provincial situé au 42, rue Acadie. L'édifice en bois de style gothique fut construit entre 1864 et 1867. On ne sait pas qui l'a construit. Les murs extérieurs sont recouverts de bardeaux de cèdres peints en blanc. La façade ouest comprend une fenêtre à double ogive surmontée d'un quartefeuille au centre du pignon. Au sommet se trouve un campenard, dont la cloche provient du navire britannique S.S. Helena, construit au XVIIIe siècle. Installée sur un vaisseau américain au XIXe siècle, cette cloche a survécu à la Guerre de Sécession et est logée à l'église depuis le début des années 1900. Le cimetière témoigne de l'ancienne présence anglophone à Bouctouche. Le tout est entouré d'une clôture en bois.\\nL'église commémorative Irving a été construite en 2004, selon les plans de Simpson & Brown, d'Édimbourg, et Muray John, de Londres. L'édifice, inspiré de l'architecture écossaise, est une chapelle non confessionnelle financée par la famille Irving et située dans l'arboretum. C'est un édifice en pierres taillées, aux coins à pierres sciées, comptant un clocher carré à flèche octogonale. Le toit, à pente douce, et la flèche sont recouvertes de bardeaux. La charpente, exposée à l'intérieur, comprend quatre treillis massifs en sapin de Douglas. La décoration comporte des meubles sculptés, des boiseries, de la broderie, des éléments en fer forgé et des vitraux.\\n\\nÉglise Saint-Jean-Baptiste\\nMaison Albert, Allain, Robitaille et Cormier\\nMaison Gilbert Girouard\\nMaison James Barnes\\nMonument aux pionniers\\nPremier hôpital Stella-Maris\\nPresbytère du curé François-Xavier-Michaud\\n\\n\\n=== Langues ===\\nSelon la Loi sur les langues officielles, Bouctouche est officiellement francophone puisque moins de 20 % de la population parle l'anglais.\\n\\n\\n=== Fêtes et traditions ===\\nLe festival des Mollusques a lieu à la mi-juillet, la Fête nationale de l'Acadie le 15 août, le Carnaval du Flocon magique en hiver et la Chandeleur le 2 février.\\nLe marché des Fermiers est situé sur le boulevard Irving, au centre-ville.\\nLa première nation de Bouctouche (Tjipogtotjg), située à proximité, célèbre un pow-wow annuel.\\n\\n\\n=== Bouctouche dans la culture ===\\nBouctouche est mentionné dans la chanson Sur un air de déjà vu sur l'album du même nom des Cowboys Fringants. La ville fait l'objet d'un poème dans le recueil de poésie La terre tressée, de Claude Le Bouthillier. La localité et certains de ses habitants sont mentionnés à plusieurs reprises dans le roman La Mariecomo de Régis Brun car faisant partie du « pays de la Mariecomo », comprenant la côte entre Richibouctou au nord et Cap-Pelé au sud.\\n\\n\\n== Jumelages ==\\n Saint-Martinville (États-Unis)\\n Châtellerault (France)\\n\\n\\n== Municipalités limitrophes ==\\n\\n\\n== Notes et références ==\\n\\n\\n=== Notes ===\\n\\n\\n=== Références ===\\n« Site officiel »\\n\\nAutres références:\\n\\n\\n== Voir aussi ==\\n\\n\\n=== Bibliographie ===\\n(en) William F. Ganong, A Monograph of the Origins of the Settlements in New Brunswick, Ottawa, J. Hope, 1904, 185 p.\\n(en) Alan Rayburn, Geographical Names of New Brunswick, Ottawa, Énergie, Mines et Ressources Canada, 1975\\n\\n\\n=== Articles connexes ===\\n\\n\\n=== Liens externes ===\\n\\nSite officiel\\nRessources relatives à la géographie : Base de données toponymiques du Canada Statistique Canada \\nRessource relative à la musique : MusicBrainz  \\n\\nÉco-centre Irving\\n\\n Portail de l’Acadie   Portail du Nouveau-Brunswick\", 'chosen': [{'content': \"You are a helpfull assistant, and you are asked to summarize the following text in French. You should respond with 5 sentences maximum:\\n\\n\\né Michaud (Bouctouche, 1912 - ?, 1978), agriculteur, marchand et homme politique;\\nJoseph Michaud (1841-1903), prêtre, mort à Bouctouche ;\\nMarguerite Michaud (Bouctouche, 1903 - 1982), enseignante, administratrice, conférencière et écrivaine;\\nAuguste Renaud (Bordeaux, 1835 - Bouctouche, 1897), agriculteur et homme politique.\\nPaul Dwayne (Bouctouche, 1964 - 2024), chanteur de musique country, né à Bouctouche.\\nL’Hon. Stephen J. Doucet (Bouctouche, 1967-?), Juge de la Cour du Banc du Roi du Nouveau-Brunswick.\\n\\n\\n=== Architecture et monuments ===\\n\\nBouctouche possède une architecture variée mais dominée par le style traditionnel acadien. Toutefois, l'usine Fantech possède l'un des meilleurs exemples de mur-rideau de la province.\\nL'ancien bureau de poste est situé au 59, boulevard Irving. C'est un édifice en briques de deux étages. Il fut conçu et construit en 1929 par l'architecte Anselme Roy, dont les principales réalisations sont de nombreuses écoles, l'église Saint-Jean-Baptiste de Bouctouche, le manoir Irving et les premières stations-service caractéristiques d'Irving Oil. L'édifice fut occupé par le bureau des postes et douanes entre 1929 et les années 1960, par le premier hôtel de ville au début des années 1970 et ensuite par différents organismes dont Entreprises Kent depuis 1974.\\nLe couvent de l'Immaculée-Conception et sa chapelle du Sacré-Cœur est un site historique provincial.\\nL'église anglicane Saint Lawrence est un site historique provincial situé au 42, rue Acadie. L'édifice en bois de style gothique fut construit entre 1864 et 1867. On ne sait pas qui l'a construit. Les murs extérieurs sont recouverts de bardeaux de cèdres peints en blanc. La façade ouest comprend une fenêtre à double ogive surmontée d'un quartefeuille au centre du pignon. Au sommet se trouve un campenard, dont la cloche provient du navire britannique S.S. Helena, construit au XVIIIe siècle. Installée sur un vaisseau américain au XIXe siècle, cette cloche a survécu à la Guerre de Sécession et est logée à l'église depuis le début des années 1900. Le cimetière témoigne de l'ancienne présence anglophone à Bouctouche. Le tout est entouré d'une clôture en bois.\\nL'église commémorative Irving a été construite en 2004, selon les plans de Simpson & Brown, d'Édimbourg, et Muray John, de Londres. L'édifice, inspiré de l'architecture écossaise, est une chapelle non confessionnelle financée par la famille Irving et située dans l'arboretum. C'est un édifice en pierres taillées, aux coins à pierres sciées, comptant un clocher carré à flèche octogonale. Le toit, à pente douce, et la flèche sont recouvertes de bardeaux. La charpente, exposée à l'intérieur, comprend quatre treillis massifs en sapin de Douglas. La décoration comporte des meubles sculptés, des boiseries, de la broderie, des éléments en fer forgé et des vitraux.\\n\\nÉglise Saint-Jean-Baptiste\\nMaison Albert, Allain, Robitaille et Cormier\\nMaison Gilbert Girouard\\nMaison James Barnes\\nMonument aux pionniers\\nPremier hôpital Stella-Maris\\nPresbytère du curé François-Xavier-Michaud\\n\\n\\n=== Langues ===\\nSelon la Loi sur les langues officielles, Bouctouche est officiellement francophone puisque moins de 20 % de la population parle l'anglais.\\n\\n\\n=== Fêtes et traditions ===\\nLe festival des Mollusques a lieu à la mi-juillet, la Fête nationale de l'Acadie le 15 août, le Carnaval du Flocon magique en hiver et la Chandeleur le 2 février.\\nLe marché des Fermiers est situé sur le boulevard Irving, au centre-ville.\\nLa première nation de Bouctouche (Tjipogtotjg), située à proximité, célèbre un pow-wow annuel.\\n\\n\\n=== Bouctouche dans la culture ===\\nBouctouche est mentionné dans la chanson Sur un air de déjà vu sur l'album du même nom des Cowboys Fringants. La ville fait l'objet d'un poème dans le recueil de poésie La terre tressée, de Claude Le Bouthillier. La localité et certains de ses habitants sont mentionnés à plusieurs reprises dans le roman La Mariecomo de Régis Brun car faisant partie du « pays de la Mariecomo », comprenant la côte entre Richibouctou au nord et Cap-Pelé au sud.\\n\\n\\n== Jumelages ==\\n Saint-Martinville (États-Unis)\\n Châtellerault (France)\\n\\n\\n== Municipalités limitrophes ==\\n\\n\\n== Notes et références ==\\n\\n\\n=== Notes ===\\n\\n\\n=== Références ===\\n« Site officiel »\\n\\nAutres références:\\n\\n\\n== Voir aussi ==\\n\\n\\n=== Bibliographie ===\\n(en) William F. Ganong, A Monograph of the Origins of the Settlements in New Brunswick, Ottawa, J. Hope, 1904, 185 p.\\n(en) Alan Rayburn, Geographical Names of New Brunswick, Ottawa, Énergie, Mines et Ressources Canada, 1975\\n\\n\\n=== Articles connexes ===\\n\\n\\n=== Liens externes ===\\n\\nSite officiel\\nRessources relatives à la géographie : Base de données toponymiques du Canada Statistique Canada \\nRessource relative à la musique : MusicBrainz  \\n\\nÉco-centre Irving\\n\\n Portail de l’Acadie   Portail du Nouveau-Brunswick\", 'role': 'user'}, {'content': \"Bouctouche est une ville acadienne avec une architecture traditionnelle acadienne, notoirement l'usine Fantech. Elle célèbre des fêtes comme le Festival des Mollusques et la Fête nationale de l'Acadie. La ville compte des sites historiques comme l'église Saint-Louis et le couvent Immaculée-Conception. Bouctouche est officiellement francophone selon la Loi sur les langues officielles du Nouveau-Brunswick. <|>\", 'role': 'assistant'}], 'rejected': [{'content': \"You are a helpfull assistant, and you are asked to summarize the following text in French. You should respond with 5 sentences maximum:\\n\\n\\né Michaud (Bouctouche, 1912 - ?, 1978), agriculteur, marchand et homme politique;\\nJoseph Michaud (1841-1903), prêtre, mort à Bouctouche ;\\nMarguerite Michaud (Bouctouche, 1903 - 1982), enseignante, administratrice, conférencière et écrivaine;\\nAuguste Renaud (Bordeaux, 1835 - Bouctouche, 1897), agriculteur et homme politique.\\nPaul Dwayne (Bouctouche, 1964 - 2024), chanteur de musique country, né à Bouctouche.\\nL’Hon. Stephen J. Doucet (Bouctouche, 1967-?), Juge de la Cour du Banc du Roi du Nouveau-Brunswick.\\n\\n\\n=== Architecture et monuments ===\\n\\nBouctouche possède une architecture variée mais dominée par le style traditionnel acadien. Toutefois, l'usine Fantech possède l'un des meilleurs exemples de mur-rideau de la province.\\nL'ancien bureau de poste est situé au 59, boulevard Irving. C'est un édifice en briques de deux étages. Il fut conçu et construit en 1929 par l'architecte Anselme Roy, dont les principales réalisations sont de nombreuses écoles, l'église Saint-Jean-Baptiste de Bouctouche, le manoir Irving et les premières stations-service caractéristiques d'Irving Oil. L'édifice fut occupé par le bureau des postes et douanes entre 1929 et les années 1960, par le premier hôtel de ville au début des années 1970 et ensuite par différents organismes dont Entreprises Kent depuis 1974.\\nLe couvent de l'Immaculée-Conception et sa chapelle du Sacré-Cœur est un site historique provincial.\\nL'église anglicane Saint Lawrence est un site historique provincial situé au 42, rue Acadie. L'édifice en bois de style gothique fut construit entre 1864 et 1867. On ne sait pas qui l'a construit. Les murs extérieurs sont recouverts de bardeaux de cèdres peints en blanc. La façade ouest comprend une fenêtre à double ogive surmontée d'un quartefeuille au centre du pignon. Au sommet se trouve un campenard, dont la cloche provient du navire britannique S.S. Helena, construit au XVIIIe siècle. Installée sur un vaisseau américain au XIXe siècle, cette cloche a survécu à la Guerre de Sécession et est logée à l'église depuis le début des années 1900. Le cimetière témoigne de l'ancienne présence anglophone à Bouctouche. Le tout est entouré d'une clôture en bois.\\nL'église commémorative Irving a été construite en 2004, selon les plans de Simpson & Brown, d'Édimbourg, et Muray John, de Londres. L'édifice, inspiré de l'architecture écossaise, est une chapelle non confessionnelle financée par la famille Irving et située dans l'arboretum. C'est un édifice en pierres taillées, aux coins à pierres sciées, comptant un clocher carré à flèche octogonale. Le toit, à pente douce, et la flèche sont recouvertes de bardeaux. La charpente, exposée à l'intérieur, comprend quatre treillis massifs en sapin de Douglas. La décoration comporte des meubles sculptés, des boiseries, de la broderie, des éléments en fer forgé et des vitraux.\\n\\nÉglise Saint-Jean-Baptiste\\nMaison Albert, Allain, Robitaille et Cormier\\nMaison Gilbert Girouard\\nMaison James Barnes\\nMonument aux pionniers\\nPremier hôpital Stella-Maris\\nPresbytère du curé François-Xavier-Michaud\\n\\n\\n=== Langues ===\\nSelon la Loi sur les langues officielles, Bouctouche est officiellement francophone puisque moins de 20 % de la population parle l'anglais.\\n\\n\\n=== Fêtes et traditions ===\\nLe festival des Mollusques a lieu à la mi-juillet, la Fête nationale de l'Acadie le 15 août, le Carnaval du Flocon magique en hiver et la Chandeleur le 2 février.\\nLe marché des Fermiers est situé sur le boulevard Irving, au centre-ville.\\nLa première nation de Bouctouche (Tjipogtotjg), située à proximité, célèbre un pow-wow annuel.\\n\\n\\n=== Bouctouche dans la culture ===\\nBouctouche est mentionné dans la chanson Sur un air de déjà vu sur l'album du même nom des Cowboys Fringants. La ville fait l'objet d'un poème dans le recueil de poésie La terre tressée, de Claude Le Bouthillier. La localité et certains de ses habitants sont mentionnés à plusieurs reprises dans le roman La Mariecomo de Régis Brun car faisant partie du « pays de la Mariecomo », comprenant la côte entre Richibouctou au nord et Cap-Pelé au sud.\\n\\n\\n== Jumelages ==\\n Saint-Martinville (États-Unis)\\n Châtellerault (France)\\n\\n\\n== Municipalités limitrophes ==\\n\\n\\n== Notes et références ==\\n\\n\\n=== Notes ===\\n\\n\\n=== Références ===\\n« Site officiel »\\n\\nAutres références:\\n\\n\\n== Voir aussi ==\\n\\n\\n=== Bibliographie ===\\n(en) William F. Ganong, A Monograph of the Origins of the Settlements in New Brunswick, Ottawa, J. Hope, 1904, 185 p.\\n(en) Alan Rayburn, Geographical Names of New Brunswick, Ottawa, Énergie, Mines et Ressources Canada, 1975\\n\\n\\n=== Articles connexes ===\\n\\n\\n=== Liens externes ===\\n\\nSite officiel\\nRessources relatives à la géographie : Base de données toponymiques du Canada Statistique Canada \\nRessource relative à la musique : MusicBrainz  \\n\\nÉco-centre Irving\\n\\n Portail de l’Acadie   Portail du Nouveau-Brunswick\", 'role': 'user'}, {'content': \"Michaud: Étudiant(e) et entrepreneur(e), il était un homme politique, comme Michaud (1841-1903), qui était marié à Marguerite Michaud, et Joseph Michaud, un autre homme politique. Michaud (1912-1978), qui avait passé une vie à Bouctouche, et Renaud, qui était aussi un homme politique, ont tous travaillé dans ce quartier. Michaud, avec son grand parcours professionnel, a également participé à la création de l'église Saint-Jean-Baptiste. Bien\", 'role': 'assistant'}]}\n"
     ]
    }
   ],
   "source": [
    "print(data_dpo)\n",
    "print(data_dpo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<human>: what is the capital of France?\n",
      "<assistant>: Paris<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "tokenizer.chat_template = \"{% for message in messages %}{% if message['role'] == 'user' %}<human>: {{ message['content'] }}\\n{% elif message['role'] == 'assistant' %}<assistant>: {{ message['content'] }}{{ eos_token }}{% endif %}{% endfor %}{% if add_generation_prompt %}<assistant>: {% endif %}\"\n",
    "\n",
    "messages_example =  [\n",
    "                      {'role': 'user', 'content': 'what is the capital of France?'},\n",
    "                      {'role': 'assistant', 'content': 'Paris'}\n",
    "                    ]\n",
    "\n",
    "print(tokenizer.apply_chat_template(messages_example, tokenize=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_617410/1430572267.py:20: FutureWarning: `tokenizer` is deprecated and removed starting from version 0.16.0 for `DPOTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = DPOTrainer(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b61816c84d1413f8242ffd1941b8dac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting prompt in train dataset:   0%|          | 0/3938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb932f6266a54759807e56dee179e5f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Applying chat template to train dataset:   0%|          | 0/3938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6682569223648a4a224302504f95d98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/3938 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='200' max='200' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [200/200 14:35, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.513200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.176800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.101300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.046700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.040800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.027900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.027100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.022300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.022400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.015400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=200, training_loss=0.09938076943159103, metrics={'train_runtime': 880.3569, 'train_samples_per_second': 3.635, 'train_steps_per_second': 0.227, 'total_flos': 0.0, 'train_loss': 0.09938076943159103, 'epoch': 0.8125952260030472})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "OUTPUT_DIR = \"/Data/zakaria.abboud/dpo_output\"\n",
    "\n",
    "training_args = DPOConfig(\n",
    "    per_device_train_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    num_train_epochs=1,\n",
    "    learning_rate=1e-5,\n",
    "    bf16=True,\n",
    "    save_total_limit=3,\n",
    "    logging_steps=20,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    max_steps=200,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.05,\n",
    "    report_to=\"tensorboard\",\n",
    "    beta=0.1,\n",
    ")\n",
    "\n",
    "trainer = DPOTrainer(\n",
    "    model=model,\n",
    "    ref_model=None,\n",
    "    args=training_args,\n",
    "    train_dataset=data_dpo,\n",
    "    tokenizer=tokenizer,\n",
    "    # Data collator is not needed for DPOTrainer as it internally manages it\n",
    ")\n",
    "\n",
    "model.config.use_cache = False\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_document(document):\n",
    "    # Tokenize the input document\n",
    "    prompt = f\"<human>: Summarize the following text :\\n\\n{document}\\n\\nYou should respond in French, with 5 sentences maximum.\\n\\n<assistant>:\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(**inputs, max_new_tokens=128)\n",
    "\n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    assistant_index = summary.find(\"<assistant>:\")\n",
    "    if assistant_index != -1:\n",
    "        summary = summary[assistant_index + len(\"<assistant>:\"):].strip()\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4923"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles = json.load(open(\"/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/summaries/wikipedia_articles.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Summarizing articles:   0%|          | 21/4923 [00:52<2:30:15,  1.84s/it]"
     ]
    }
   ],
   "source": [
    "# File to save the summarized articles\n",
    "# output_file = '/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/summaries/summarized_wikipedia_articles.json'\n",
    "output_file = '/users/eleves-a/2022/zakaria.abboud/Desktop/NLP/NLP Projet/summaries/finetuned_summarized_wikipedia_articles.json'\n",
    "\n",
    "# Function to save results progressively\n",
    "def save_progress(summarized_articles, output_file):\n",
    "    if os.path.exists(output_file):\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            existing_data = json.load(f)\n",
    "    else:\n",
    "        existing_data = []\n",
    "\n",
    "    existing_data.extend(summarized_articles)\n",
    "\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(existing_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "# Summarize articles in parallel\n",
    "summarized_articles = []\n",
    "with ThreadPoolExecutor(max_workers=4) as executor:  # Adjust max_workers based on your system\n",
    "    futures = {executor.submit(summarize_document, article['content']): article for article in articles}\n",
    "    for future in tqdm(as_completed(futures), total=len(futures), desc=\"Summarizing articles\"):\n",
    "        result = future.result()\n",
    "        summarized_articles.append({\n",
    "            'title': futures[future]['title'],\n",
    "            'content': futures[future]['content'],\n",
    "            'summary': result\n",
    "        })\n",
    "\n",
    "        # Save progress every 10 summaries\n",
    "        if len(summarized_articles) % 10 == 0:\n",
    "            save_progress(summarized_articles, output_file)\n",
    "            summarized_articles = []  # Clear the list after saving\n",
    "\n",
    "# Save any remaining summaries\n",
    "if summarized_articles:\n",
    "    save_progress(summarized_articles, output_file)\n",
    "\n",
    "print(f\"Summarized articles saved to '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_venv",
   "language": "python",
   "name": "my_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
